#!/bin/bash
# -*- mode: shell-script -*-
#
# group all shell commands in a single file
# you can run any of the inside functions with e.g.
#

# terminology
# (*) course refers to a course name as found under NBHROOT/courses
# (*) student refers to a UNIX login name, and is identical
# to the names used under NBHROOT when referring to a student
# (*) container is the name of a container as known to docker
#
# conventions
# (*) functions designed to be exposed to the outside
#     are declared with @declare-subcommand
# (*) some other minor subcommands are available
#     they start with a lowercase, but are not declared
#     as subcommands
# (*) internal-only functions start with a dash -
#
#
# NOTES about systemd-nspawn:
#
# (*) there remains in here some leftovers of a rough attempt
#     that I made at using systemd-nspawn as a replacement to docker
#     this was never finished, although we were probably close
#     all this was commented off in Jan. 2018
# (*) in this approach we still used docker but just for doing image
#     snapshots
# (*) the IMAGES and MACHINES globals are only used for this
#     systemd-nspawn variant, which was never finished
#     although we were probably close
# (*) missing was a suitable strategy for setuid
#     as linux user namespaces looks a little overkill
# (*) using the same approach to setuids as the one eventually
#     adopted for docker (i.e. start-in-dir-as-uid) should probably
#     be rather straightforward with systemd-nspawn too
#
# NOTE about interactions between shell and python
# sometimes we need to probe for data that is in the python world
# for this we use django management commands, that are accessible from
# the shell as /usr/bin/nbh-manage, which is a simple copy of django/manage.py
########################################


# nbh-driver
COMMAND=$0

# the default values for a few globals
NBHROOT=${NBHROOT:-/nbhosting}
DEBUG=

# miss options to tweak these - which relate to systemd-nspawn
#IMAGES=/homefs/btrfs/btrfs
#MACHINES=/homefs/btrfs/machines

### various timeouts
# how long to wait for the port number to show up after a start
# this is 10 times .1s so 1s - proceed immediately
timeout_wait_for_port="10 .1 0"

# how long should we wait for the container to answer http
# trying to create 6 containers at the exact same time : 10 is not long enough
# then we wait an extra safety timeout
timeout_wait_for_http="20 1 3"

# implementation note
#  don't do set -e, as it may cause the program to exit abruptly
# and we need to make sure we output exactly one line with 4 tokens

########## for listing available subcommands
SUBCOMMANDS=""
function @declare-subcommand() {
    subcommand=$1; shift
    SUBCOMMANDS="$SUBCOMMANDS $subcommand"
}

############################## helpers
function -echo-stderr() {
    >&2 echo $(date "+%H:%M:%S") "$@"
}

function -die() {
    -echo-stderr "$@"
    exit 1
}


########################################
# devel/tests/-oriented
########################################

function clear-docker-kill() {
    containers=$(docker ps --format '{{.Names}}')
    for c in $containers; do
        echo "Killing $c"
        docker kill $c
    done
}

function clear-docker-rm() {
    containers=$(docker ps -a --format '{{.Names}}')
    for c in $containers; do
        echo "Removing $c"
        docker rm $c
    done
}

# we assume students hashes are 32 chars long
function clear-etc-passwd() {
    users=$(egrep '[0-9a-f]{32}' /etc/passwd | awk -F: '{print $1;}')
    for user in $users; do
        echo "Removing user $user from /etc/passwd"
        del-student $user
    done
}

# run on the box that is about to become the production box
function prepare-swap() {
    clear-docker-kill
    clear-docker-rm
    clear-etc-passwd
    echo "WARNING: this script does not take care of the courses area"
}

##
function list-tests() {
    echo ==================== "(all)" dockers
    docker ps -a --format {{.Names}} | grep -- '-x-student-'
    echo ==================== users
    grep student- /etc/passwd
    echo ==================== user dirs
    ls -d /nbhosting/students/student-* 2> /dev/null
}

function clear-tests() {
    for userdir in $(ls -d /nbhosting/students/student-* 2>/dev/null); do
        user=$(basename $userdir)
        for coursedir in $(ls -d $userdir/* 2>/dev/null); do
            course=$(basename $coursedir)
            docker=${course}-x-${user}
            echo killing $docker
            docker kill $docker >& /dev/null
            echo removing $docker
            docker rm $docker >& /dev/null
        done
        echo deleting user $user
        del-student $user
    done
}

########################################
# runtime
########################################

# create directory/ies leading to file <file>
function -mkdir-for-file-as-student () {
    [ "$#" -eq 2 ] || -die $FUNCNAME requires 2 args
    local filename=$1; shift
    local login=$1; shift

    local dir=$(dirname $filename)
    [ -d $dir ] || {
        -echo-stderr ID=$(id)
        -echo-stderr Creating directory $dir for $filename
        mkdir -p $dir
        -echo-stderr Giving $dir to $login
        chown $login:$login $dir
    }
}

# create symlink right where the notebook is, not only at the top
function -create-symlink-at-file () {
    [ "$#" -eq 3 ] || -die $FUNCNAME requires 3 args
    local filename=$1; shift
    local localname=$1; shift
    local destination=$1; shift

    local dir=$(dirname $filename)
    # the symlink should
    # be in dir/ (like filename)
    # be named localname
    # and point at destination
    local source=$dir/$localname
    [ -h $destination ] || -echo-stderr creating static symlink $destination
    ln -sf $destination $source
}


############################## admin
function list-tree() {
    find $NBHROOT -type d | fgrep -v '/.git/'
}

function status-docker() {
    echo ========== CONTAINERS
    local running=$(docker ps | grep -v '^CONTAINER' | wc -l)
    local total=$(docker ps -a | grep -v '^CONTAINER' | wc -l)
    echo "$running running / $total total containers"
}


function status-users() {
    echo ========== USERS and GROUPS
    local users=$(grep '^[^:]*:[^:]*:[0-9][0-9][0-9][0-9]' /etc/passwd | grep -v '^nfsnobody' | wc -l)
    local groups=$(grep '^[^:]*:[^:]*:[0-9][0-9][0-9][0-9]' /etc/group | egrep -v '^(nfsnobody|docker)' | wc -l)
    echo "$users users in /etc/passwd - $groups groups in /etc/group"
}


function status-tree() {
    echo ========== CONTENTS of $NBHROOT
    local students=$(ls $NBHROOT/students | wc -l)
    local courses_git=$(ls $NBHROOT/courses-git | wc -l)
    local courses=$(ls $NBHROOT/courses | wc -l)
    echo "$students students - $courses_git course repos - $courses actual courses"
    local logfiles=$(find $NBHROOT/logs -type f| wc -l)
    echo "$logfiles log files under $NBHROOT/logs"
    local rawfiles=$(find $NBHROOT/raw -type f| wc -l)
    echo "$rawfiles raw files under $NBHROOT/raw"
}

# provide some info on the various pieces
@declare-subcommand admin-status
function admin-status() {
    status-users "$@"
    status-docker "$@"
    status-tree "$@"
}


############################## course management
function -compute-course-globals() {
    [ "$#" -eq 1 ] || -die $FUNCNAME requires 1 arg
    local course=$1; shift
    COURSE_git=$NBHROOT/courses-git/$course

    COURSE_notebooks=$NBHROOT/courses/$course
    COURSE_imagefile=$COURSE_notebooks/.image
    COURSE_stafffile=$COURSE_notebooks/.staff
    COURSE_giturlfile=$COURSE_notebooks/.giturl
    COURSE_modules=$NBHROOT/modules/$course
    COURSE_jupyter=$NBHROOT/jupyter/$course
    COURSE_static=$NBHROOT/static/$course
    COURSE_raw=$NBHROOT/raw/$course

    COURSE_logs=$NBHROOT/logs/$course

#    # for systemd-nspawn
#    COURSE_ref=$MACHINES/$course.ref

    COURSE_build=$NBHROOT/images/$course

    # read settings files
    COURSE_static_mappings=$(nbh-manage course_static_mappings $course 2> /dev/null)
    COURSE_static_toplevels=$(nbh-manage course_static_toplevels $course 2> /dev/null)
    COURSE_image=$(cat $COURSE_imagefile 2> /dev/null)
    COURSE_giturl=$(cat $COURSE_giturlfile 2> /dev/null)
}


# clone from upstream git repo
# and updates the various parts accordingly

@declare-subcommand course-init
function course-init() {
    local USAGE="Usage: $COMMAND $FUNCNAME course giturl"
    [ "$#" -eq 2 ] || -die $USAGE

    local course=$1; shift
    local giturl=$1; shift

    -compute-course-globals $course

    local log=$COURSE_logs/000.log

    function -course-init() {
        [ -d $COURSE_git ] && -die "Course already present as $COURSE_git"

        echo ==========  $(date): course-init from $giturl
        local courses_git_parent=$(dirname $COURSE_git)
        mkdir -p $courses_git_parent
        cd $courses_git_parent
        echo In $(pwd) : running git clone $giturl $course
        git clone $giturl $course
    }

    [ -d $COURSE_logs ] || mkdir -p $COURSE_logs
    -course-init >> $log 2>&1
    # run these automatically to avoid various frustrations
    course-settings $course >> $log 2>&1
    course-update-from-git $course >> $log 2>&1
}


##########
# CLI to set course attributes/settings
###

@declare-subcommand course-settings
function course-settings() {
    local USAGE="Usage: $COMMAND $FUNCNAME  [-i image] [-s staff-hash] course
      -i : specify the docker image to use for that course
      -s : (cumulative) add staff hash - staff members are ignored in stats
"

    local image=""
    local staff=""
    while getopts "i:s:" option; do
        case $option in
            i) image="$OPTARG" ;;
            s) staff="$staff $OPTARG" ;;
            ?) -die "$USAGE" ;;
        esac
    done
    shift $((OPTIND-1))
    # reset OPTIND for subsequent calls to getopts
    OPTIND=1

    [ "$#" -eq 1 ] || -die $USAGE

    course=$1; shift
    -compute-course-globals $course

    ### update the course settings

    # image name: redefine or create
    if [ -n "$image" ]; then
        echo $image > $COURSE_imagefile
    elif [ ! -f $COURSE_imagefile ]; then
        echo $course > $COURSE_imagefile
    fi

    # augment or init -  for staff members
    if [ -n "$staff" ]; then
        for hash in $staff; do
            echo $hash >> $COURSE_stafffile
        done
    elif [ ! -f $COURSE_stafffile ]; then
        touch $COURSE_stafffile
    fi

    # convenience: update .giturl
    if [ ! -f $COURSE_giturlfile ]; then
        (cd $COURSE_git; git config --get remote.origin.url) > $COURSE_giturlfile
    fi

}


##########
# pull from upstream git repo
# and updates the various parts accordingly
# also the options allow to change global settings
# for the course:
###
@declare-subcommand course-update-from-git
function course-update-from-git() {
    local USAGE="Usage: $COMMAND $FUNCNAME course"

    [ "$#" -eq 1 ] || -die $USAGE

    course=$1; shift
    -compute-course-globals $course

    # just a convenience so that these get initialized
    course-settings $course

    local log=$NBHROOT/logs/$course/update.log

    # check the course is known
    [ -d $COURSE_git ] || -die "Cannot find git repo $COURSE_git"
    # initialize
    [ -d $COURSE_notebooks ] || {
        echo Creating notebooks dir $COURSE_notebooks
        mkdir -p $COURSE_notebooks
    }

    rsync="rsync --recursive --copy-unsafe-links --perms --times --force --delete"

    function -update-course() {

        [ -d $COURSE_git ] || -die "$FUNCNAME: $course has not git repo in $COURSE_git - aborting"

        echo ==========  $(date): update-course

        cd $COURSE_git
        echo "========== git pull"
        git pull
        # this does not always show 3 commits
        # so let's be more vague about that
        echo "========== latest commits"
        git log --oneline "HEAD~~~..HEAD"
        echo "========== dealing with submodules"
        # might not be exactly needed anymore if we use subtrees instead
        git submodule init
        git submodule update

        echo "========== housekeeping"
        # create course dirs if needed
        for dir in $COURSE_notebooks $COURSE_modules $COURSE_static $COURSE_raw; do
            [ -d $dir ] || { echo Creating $dir; mkdir -p $dir; }
        done

        # clear track caches
        rm -rf $COURSE_notebooks/tracks.json

        ##### notebooks
        # temporary; making sure we do clean stuff up properly
        rm -rf $COURSE_notebooks/*
        $rsync --prune-empty-dirs --include='*.ipynb' --include='*/' --exclude='*' \
        $COURSE_git/ $COURSE_notebooks/
        ##### modules
        [ -d modules ] && { $rsync modules/ $COURSE_modules; chmod -R g-w,o-w $COURSE_modules; }
        ##### static
        for toplevel in $COURSE_static_toplevels; do
            $rsync $toplevel $COURSE_static; chmod -R g-w,o-w $COURSE_static;
        done
        ##### jupyter
        [ -d $COURSE_jupyter ] || mkdir -p $COURSE_jupyter
        for file in jupyter_notebook_config.py custom.js custom.css; do
            [ -f $COURSE_jupyter/$file ] || touch $COURSE_jupyter/$file
        done
    }

    [ -d $COURSE_logs ] || mkdir -p $COURSE_logs
    -update-course 2> >(tee -a $log >&2)
}

####################
# build a docker image
@declare-subcommand course-build-image
function course-build-image() {
    local USAGE="Usage: $COMMAND $FUNCNAME [-f] course
this command will
. locate a dockerfile, either in the course git repo,
  or under images/ in nbhosting
. (re)build the course docker image based on that

With the -f option, rebuild will be forced; that is to say, docker build
  is invoked with the --no-cache option.
  Of course this means a longer execution time.
"

    local force_tag=""
    while getopts "f" option; do
        case $option in
            f) force_tag="--no-cache" ;;
            ?) -die $USAGE ;;
        esac
    done
    shift $((OPTIND-1))
    OPTIND=1

    [ "$#" -eq 1 ] || -die $USAGE
    local course="$1"; shift

    -compute-course-globals $course

    mkdir -p $COURSE_build
    cd $COURSE_build
    echo "Building image ${COURSE_image} in ${COURSE_build} ${force_tag}"

    ########## locate
    c1="$COURSE_git/nbhosting/Dockerfile"
    c2="$NBHROOT/images/$course.Dockerfile"
    dockerfile=""
    for c in $c2 $c1; do
        [ -f $c ] && dockerfile=$c
    done

    if [ -z "$dockerfile" ]; then
        echo "$FUNCNAME: cannot locate dockerfile among:"
        for c in $c1 $c2; do echo "candidate $c"; done
        exit 1
    fi

    if [ "$dockerfile" == $c1 ]; then
        rsync -aid $(dirname $c1)/ ${COURSE_build}/
    fi
    echo "Installing $dockerfile in ${COURSE_build}"
    cp $dockerfile $COURSE_build/nbhosting.Dockerfile
    echo "Installing start-in-dir-as-uid.sh in ${COURSE_build}"
    cp $NBHROOT/images/start-in-dir-as-uid.sh ${COURSE_build}
    docker build ${force_tag} -f nbhosting.Dockerfile -t $COURSE_image .

}

####################
function -check-course() {
    local course=$1; shift
    -compute-course-globals $course
    [ -d $COURSE_notebooks ] || -die "No such course $course"
}


# a lot to say here:
# * it's unclear if we need to do the rsync here or not
#   some course might wish to provide their own custom*
# * the copy into a course-dependant location
#   looks extraneous but it might come in handy some day
# * finally this layout is painfully confusing..
#
function -check-course-jupyter() {
    local USAGE="Usage: $COMMAND $FUNCNAME course"
    [ "$#" -eq 1 ] || -die $USAGE
    course=$1; shift
    -compute-course-globals $course
    [ -d $COURSE_jupyter ] || mkdir -p $COURSE_jupyter
    # temporary : if we find a file named 'DETACHED' in /nbhosting/jupyter/course/
    # then we leave that alone; otherwise, keep that in sync with our sources
    if [ -f $COURSE_jupyter/DETACHED ]; then
        -echo-stderr "Leaving jupyter material for $course intact (DETACHED found)"
    else
        for file in jupyter_notebook_config.py custom.js custom.css; do
            rsync -tp $NBHROOT/jupyter/$file $COURSE_jupyter/
        done
    fi
}


############################## unix accounts and containers
function -compute-student-globals-in-course () {
    student=$1; shift
    course=$1; shift
    STUDENT_home=$NBHROOT/students/$student
    STUDENT_course=$STUDENT_home/$course
    STUDENT_modules=$STUDENT_course/modules
    STUDENT_log=$NBHROOT/logs/$course/create-$student.log

    STUDENT_container="${course}-x-${student}"

    [ -d $STUDENT_course ] || sudo -u $student mkdir -p $STUDENT_course
}


@declare-subcommand add-student-in-course
function add-student-in-course() {
    local USAGE="Usage: $COMMAND $FUNCNAME student course"
    [ "$#" -eq 2 ] || -die $USAGE

    # typically of the form <course>-nnnnn
    local student=$1; shift
    # course name
    local course=$1; shift

    -echo-stderr $FUNCNAME $student $course - in $(pwd) as $(id)

    # create students root if not yet present
    [ -d $NBHROOT/students ] || mkdir -p $NBHROOT/students

    STUDENT_home=$NBHROOT/students/$student

    # when swapping back and forth between dev and prod
    # we may have a home dir already created  - by rsyncing data
    # during the swap - while the user in question is not yet known
    # in /etc/passwd; this is why we manage homedir creation explicitly
    #
    [ -d $STUDENT_home ] || {
        mkdir $STUDENT_home
    }

    # check login existence
    getent passwd $student >& /dev/null || {
        -echo-stderr Creating disabled login $student
        useradd --user-group --no-create-home --home-dir $STUDENT_home $student || {
            -echo-stderr Failed to create login $student - aborting;
            return 1
        }
        # disable login
        usermod -L $student
    }

    # always chown that homedir for safety
    chown -R $student:$student $STUDENT_home

    # add user to both groups docker and course
    for group in docker $course; do
        # check group existence
        getent group $group >& /dev/null || {
            -echo-stderr Creating group $group
            groupadd $group
        }
        -echo-stderr "Ensuring $student is in group $group"
        groupmems -a $student -g $group &> /dev/null
        # docker start would be way too intrusive !
        if [ $? != 0 -a "$group" == "docker" ]; then
            -echo-stderr "reloading docker service after adding $student into docker"
            systemctl reload docker
        fi
    done

    return 0

}


##########
# delete unix account
# xxx would need to properly stop/rm any attached container
# which might be easy if we use the same name for the student and the container
function del-student() {
    local USAGE="Usage: $COMMAND $FUNCNAME student"
    [ "$#" -eq 1 ] || -die $USAGE
    # the unix login name
    local student=$1; shift
    # xxx ...
    userdel --remove --force $student
}


# make sure the student has a copy of the nodebook
@declare-subcommand check-student-notebook-for-course
function check-student-notebook-for-course() {
    local USAGE="Usage: $COMMAND $FUNCNAME [-f] student notebook course"

    local forcecopy=""
    while getopts "f" option; do
        case $option in
            f) forcecopy="-f" ;;
            ?) -die "$USAGE" ;;
        esac
    done
    shift $((OPTIND-1))
    # reset OPTIND for subsequent calls to getopts
    OPTIND=1

    [ "$#" -eq 3 ] || -die $USAGE
    student=$1; shift
    notebook=$1; shift
    course=$1; shift

    [ -n "$DEBUG" ] && set -x

    -compute-course-globals $course
    -compute-student-globals-in-course $student $course

    local course_notebook=$COURSE_notebooks/$notebook
    local student_notebook=$STUDENT_course/$notebook

    # copy if student notebook is missing, or if force is requested
    if [ ! -f $student_notebook ] || [ -n "$forcecopy" ]; then
        -mkdir-for-file-as-student $student_notebook $student
        -echo-stderr "Cloning $student_notebook from $COURSE_notebook (forcecopy=$forcecopy)"
        # use rsync for preserving creation time
        sudo -u $student rsync -tp $course_notebook $student_notebook
    else
        [ -n "$DEBUG" ] && -echo-stderr Student copy $student_notebook is fine
    fi

    # do this no matter what for easier deployment
    for mapping in $COURSE_static_mappings; do
        # expose() uses :: to separate
        local from_top=$(sed -e 's,::.*,,' <<< $mapping)
        local    local=$(sed -e 's,.*::,,' <<< $mapping)
        -create-symlink-at-file $student_notebook $local /home/jovyan/static/$from_top
    done

    # nothing else is required in the student's work area
    # the rest (modules/ for code, and static/)
    # will be bind-mounted in the docker container
}

##########
# create a docker container
# the student is expected to have been created with enroll-student-in-course
# beforehand (so the unix account and homedir exists)
#
# write on stdout a single action word that is either
# * stage1 action=created
# * stage1 action=existing
@declare-subcommand docker-create-container-for-student-in-course
function docker-create-container-for-student-in-course() {
    local USAGE="Usage: $COMMAND $FUNCNAME container student course"

    [ "$#" -eq 3 ] || -die "$USAGE"

    # container name - if it exists then nothing happens here
    local container=$1; shift
    # student name aka student - should exist as /nbhosting/students/$student
    local student=$1; shift
    # course name - should exist as /nbhosting/courses/$course
    # i.e. should have gone through course-init and update-course
    local course=$1; shift

    -compute-course-globals $course
    -compute-student-globals-in-course $student $course

    # rain check
    [ -d $STUDENT_home ] || -die student dir not found $STUDENT_home
    [ -d $COURSE_nbroot ] || -die course notebooks dir not found $COURSE_nbroot
    [ -f $COURSE_notebook ] || -die master notebook not found in course $COURSE_notebook
    [ -d $COURSE_modules ] || -echo-stderr WARNING $COURSE_modules dir not found
    for toplevel in $COURSE_toplevels; do
        local static_toplevel=$NBHROOT/static/$course/$toplevel
        [ -d $static_toplevel ] || -echo-stderr WARNING $static_toplevel dir not found
    done

    docker inspect --type image $COURSE_image >& /dev/null ||\
        -die image $COURSE_image not known to docker

    [ -n "$DEBUG" ] && set -x

    # update jupyter_notebook_config.py and the 2 custom files
    -check-course-jupyter $course

    # touch a file in the student's course dir
    # so the monitoring tool can spare it
    # <=> jupyter's root
    touch $STUDENT_course/.monitor

    local jupyter_token=$container
    # check if container container is already defined
    if docker inspect --format "{{.Name}}" $container >& /dev/null ; then
        action="existing"
        # this is the case where docker inspect was successful
    else
        action="created"
        # this now is when docker inspect fails
        -echo-stderr Creating docker container $container
        # * map host free port to fixed 8888 in container
        # * bind  mounts so that the user's data is on
        #   the host filesystem
        # * we mount the directory /home/jovyan/.jupyter as a whole
        #   instead as mounting the 2 files custom.js and custom.css individually
        #   this is an attempt to ease propagation of changes to any of these files
        #   as otherwise a container restart is required for this to take effect
        # * map jovyan uid to the student's
        #   out of luck trying to use docker-stacks's native start.sh
        #   that led to costly and useless chown's on /opt/conda; so instead we
        #   * run the container as root
        #   * in turn use our own script start-in-dir-as-uid.sh
        #     from ../docker/images that does runuser to have jupyter
        #     run as the right uid; of course this means it is a requirement
        #     for the course images to contain that script
        # * turn off this http header that otherwise would prevent
        #   embedding in a FUN iframe
        #   Content-Security-Policy: frame-ancestors 'self';
        #        ... report-uri /api/security/csp-report
        #   so set the web server's settings to clear the
        #   Content-Security-Policy header it is too tedious on the command line
        #   with quoting and all, so we use jupyter's config file instead in
        #   jupyter/jupyter_notebook_config.py
        # * set NBAUTOEVAL_LOG to a file that ends up on the host filesystem the
        #   default for NBAUTOEVAL_LOG is $HOME/.nbautoeval, which in this context
        #   does not even make sense - $HOME is unset. Even if it was if would not
        #   reside on the host filesystem.
        #
        # compute student uid
        STUDENT_uid=$(id -u $student)

        command="docker create --name $container
                 --publish 8888
                 --user root
                 --env NBAUTOEVAL_LOG=/home/jovyan/work/.nbautoeval
                 -v $STUDENT_course:/home/jovyan/work
                 -v $COURSE_jupyter/jupyter_notebook_config.py:/home/jovyan/.jupyter/jupyter_notebook_config.py:ro
                 -v $COURSE_jupyter:/home/jovyan/.jupyter/custom:ro
                 -v $COURSE_modules:/home/jovyan/modules:ro
                 -v $COURSE_static:/home/jovyan/static:ro
"
        # see start-in-dir-as-uid.sh for a note on setting the directories
        # below
        # note that setting the ip here is a workaround
        # for a broken jupyter/docker-stacks version around late 2018
        # probably not needed with more recent ones
        command="$command
                 -e PYTHONPATH=/home/jovyan/modules
                 $COURSE_image
                 start-in-dir-as-uid.sh /home/jovyan $STUDENT_uid
                 jupyter notebook
                 --ip=0.0.0.0
                 --no-browser
                 --NotebookApp.notebook_dir=/home/jovyan/work
                 --NotebookApp.token=$jupyter_token

"
        [ -n "$DEBUG" ] && command="$command --log-level=DEBUG"
        # show command for manual debugging
        -echo-stderr XXXXXXXXXX $command
        # we need a clean stdout : redirect stdout to stderr
        >&2 $command
    fi

    -echo-stderr $FUNCNAME writes action=$action
    echo $action
    return 0
}

####################
# xxx probably a lot of space for improvement here
# retrieve port from output like this
# map[8888/tcp:[{0.0.0.0 32774}]]
function get-docker-container-port() {
    local USAGE="Usage: $COMMAND $FUNCNAME container"
    [ "$#" -eq 1 ] || -die $USAGE

    local container=$1; shift
    docker inspect --format '{{.NetworkSettings.Ports}}' $container | cut -d' ' -f 2 | sed -e 's,[^0-9],,g'
}

# if the container was just started it may take a little time
# before we can know on what port it runs
# PS: it's not even clear it's useful to do this loop...
function -find-docker-port-number() {
    local container=$1; shift
    local ticks=$1; shift
    local period=$1; shift
    local extra=$1; shift
    local counter=1
    while [ $counter -le $ticks ]; do
        -echo-stderr "Probing for port ($counter)"
        docker_port=$(get-docker-container-port $container)
        [ -n "$docker_port" ] && {
            sleep $extra
            echo $docker_port;
            return 0;
        }
        counter=$(( $counter + 1))
        sleep $period
    done
    -echo-stderr "find-docker-port-number failed after $counter iterations"
    return 1
}

# in particular the actual timeout is unclear
function -wait-for-http-on-port-token() {
    local port=$1; shift
    local token=$1; shift
    local ticks=$1; shift
    local period=$1; shift
    local extra=$1; shift
    local counter=1
    while [ $counter -le $ticks ]; do
        -echo-stderr "Waiting for TCP ($counter) on port $port"
        # first check if tcp port is up
        if timeout 1 bash -c "cat < /dev/null > /dev/tcp/localhost/$port" 2> /dev/null; then
            # if so, check that http is ready
            -echo-stderr "Checking for HTTP ($counter) on port $port"
            curl "http://localhost:$port/tree?token=$token" >& /dev/null && {
                # sleep an extra .5 s to be safe
                sleep $extra
                -echo-stderr HTTP OK
                return 0
            }
        fi
        counter=$(( $counter + 1))
        sleep $period
    done
    -echo-stderr "timeout expired after $counter iterations"
    return 1
}


####################
# we create the container with docker create -p 8888
# this way the container can be stopped and then restarted
# with a fresh (unused) port each time
#
# possible resulting values for action
# * stage2 action=failed-unknown-container
# * stage2 action=failed-timeout
# * stage2 action=running
# * stage2 action=restarted

@declare-subcommand docker-start-container
function docker-start-container() {
    local USAGE="Usage: $COMMAND $FUNCNAME container"
    [ "$#" -eq 1 ] || -die $USAGE

    local container="$1"; shift

    [ -n "$DEBUG" ] && set -x

    # touch a file in the student's course dir
    # so the monitoring tool can spare it
    # <=> jupyter's root
    touch $STUDENT_course/.monitor

    local jupyter_token=$container
    # check if container container is already defined
    if ! docker inspect --format "{{.Name}}" $container >& /dev/null; then
        -echo-stderr "INTERNAL error: cannot start non-existent container $container"
        action="failed-unknown-container"
        echo $action $container 0 none
        return
    fi

    ### at that point the docker is created
    # start the container only if it needs to, and in that
    # case wait until it's up and reachable
    running=$(docker inspect -f "{{.State.Running}}" $container)
    # refine action if this container was not just created
    action=$([ "$running" == true ] && echo running || echo restarted)

    # actually restart if needed
    if [ "$running" != "true" ]; then
        -echo-stderr Starting container $container
        # prevent clobbering of stdout
        >&2 docker start $container
    fi

    # figure out on what port it runs; wait for a second (10 times .1)
    docker_port=$(-find-docker-port-number $container $timeout_wait_for_port)

    # wait until the service actually serves HTTP requests
    # we need to do this only if we have just started it
    if [ "$running" != "true" ]; then
        -wait-for-http-on-port-token \
            $docker_port $jupyter_token $timeout_wait_for_http || {
            # show docker logs on stderr
            -echo-stderr "==================== dockers logs on that container over the last 2 minutes"
            >&2 docker logs -t --since +2m $container
            action="failed-timeout"
        }
    fi

    # this is the only thing that goes on stdout
    #
    echo $action $docker_port $jupyter_token

    [ -n "$DEBUG" ] && set +x
}


# ENTRY POINT: this is the single entry point to edxfront.views

@declare-subcommand docker-view-student-course-notebook
function docker-view-student-course-notebook() {
    local USAGE="Usage: $COMMAND $FUNCNAME [-f] student course notebook"

    local forcecopy=""
    while getopts "f" option; do
        case $option in
            f) forcecopy="-f" ;;
            ?) -die "$USAGE" ;;
        esac
    done
    shift $((OPTIND-1))
    # reset OPTIND for subsequent calls to getopts
    OPTIND=1

    [ "$#" -eq 3 ] || -die $USAGE
    local student=$1; shift
    local course=$1; shift
    local notebook=$1; shift

    ## just in case is was never done before
    -check-course $course
    # update jupyter_notebook_config.py and the 2 custom files
    -check-course-jupyter $course

    ## in case the student is not known yet
    add-student-in-course $student $course || {
        # something wrong happened, typically /etc/login.defs misconfigured
        echo failed none none none
        return 1
    }

    ## create the student notebook if not there yet
    check-student-notebook-for-course $forcecopy $student $notebook $course

    -compute-student-globals-in-course $student $course

    # create and start the container
    local container=$STUDENT_container
    # either existing of created
    action1=$(docker-create-container-for-student-in-course $container $student $course)
    line2=$(docker-start-container $container)

    # report: the action depends on both stages
    local action2=$(cut -d' ' -f1 <<< $line2)
    local port=$(cut -d' ' -f2 <<< $line2)
    local token=$(cut -d' ' -f3 <<< $line2)

    case $action2 in
        failed*)
            action=$action2;;
        *)
            case $action1 in
                created) action=$action1;;
                *) action=$action2;;
            esac;;
    esac
    echo $action $container $port $token

    return 0
}


#################### share a static version
# there here is the implicit assumption that the student
# has opened a private notebook at least once
#
# write a single line that is the path to use to reach the snapshot
#
@declare-subcommand docker-share-student-course-notebook-in-hash
function docker-share-student-course-notebook-in-hash() {
    local USAGE="Usage: $COMMAND $FUNCNAME student course notebook hash"
    [ "$#" -eq 4 ] || -die $USAGE
    local student=$1; shift
    local course=$1; shift
    local notebook=$1; shift
    local hash=$1; shift

    -compute-course-globals $course
    -compute-student-globals-in-course $student $course

    [ -n "$DEBUG" ] && set -x

    # host side -
    local host_notebook=$STUDENT_course/$notebook
    [ -f $host_notebook ] || -die "Student notebook not found in $host_notebook"

    # container side -
    local guest_notebook="work/$notebook"

    # input here refers to the container
    local container_command="jupyter nbconvert --to html  --stdout $guest_notebook"

    # the relative path for the http server (see nginx/nbhosting.conf)
    local url_path=/snapshots/$course/$hash.html
    # where to store the result in host
    local absolute_path=/var/nginx/nbhosting/$url_path
    -mkdir-for-file-as-student $absolute_path nginx

    docker exec $STUDENT_container $container_command > $absolute_path

    echo $url_path
}


#################### helpers

@declare-subcommand admin-docker-enter
function admin-docker-enter() {
    local USAGE="Usage: $FUNCNAME container"
    [ "$#" -eq 1 ] || -die $USAGE
    local container=$1; shift

    docker exec -ti $container /bin/bash
}

#
# this will destroy any notebook in the workspace
# of any student declared as a staff member
# this is helpful so that all the staff always has
# the latest version, and does not see artefacts
# due to past activity; for example, imagine a notebook
# is renamed in git but there is a dangling reference in
# edx to the old name
#
@declare-subcommand course-clear-staff
function course-clear-staff() {
    local USAGE="Usage: $FUNCNAME course"
    [ "$#" -eq 1 ] || -die $USAGE

    local course=$1; shift
    -compute-course-globals $course
    # 'student' is used by FUN's studio
    staffs="student $(cat $COURSE_stafffile)"
    for staff in $staffs; do
        -compute-student-globals-in-course $staff $course
        notebooks=$(find $STUDENT_course -name '*.ipynb')
        if [ -z "$notebooks" ]; then
            echo "=== no notebook found in $STUDENT_course"
        else
            echo "Cleaning private notebooks in $STUDENT_course"
            for notebook in $notebooks; do
                echo '>>>' $notebook
            done
            rm -f $notebooks
        fi
    done
}


#
# once a course is over it is safe to remove all containers
# attached to that course
#
# NOTES:
# * because dockerd handles one request at a time
#   and so effectively sequentialize all these destruction requests
#   this is likely to take hours or even days..
# * also the may to locate containers is based on the course name
#   in a somewhat inclusive way; it can be a bit inaccurate if I
#   have for instance 2 courses python and thepython
#   but only stopped containers will be removed
#   so it is not too big a deal
# * by default, only containers that have exited
#   more than one month ago are removed
#   with the -a option, all such containers are removed

@declare-subcommand course-clean-containers
function course-clean-containers() {
    local USAGE="Usage: $FUNCNAME [-a] course"
    [[ -z "$#" ]] && -die $USAGE
    local kill_all=""
    while getopts ":a" opt; do
        case $opt in
            a) kill_all=true;;
            *) -die $USAGE;;
        esac
    done
    shift $(($OPTIND-1))

    [ "$#" -eq 1 ] || -die $USAGE

    local course=$1; shift
    local pattern="${course}-x-"
    while true; do
        local focus
        if [ -n "$kill_all" ]; then
            focus=$(docker ps -a \
                    --filter 'status=exited' \
                    --filter "name=$pattern" \
                    --format '{{.Names}}' \
                    | head -1)
        else
            focus=$(docker ps -a \
                    | grep "$pattern" \
                    | grep 'Exited.*month.*ago' \
                    | awk '{print $NF;}' \
                    | head -1)
        fi
        # we're done
        [ -z "$focus" ] && break
        # otherwise remove it
        #echo $FUNCNAME removing container $focus
        docker rm $focus
    done
}


@declare-subcommand course-list-kernels
function course-list-kernels() {
    local USAGE="Usage: $FUNCNAME course [containers]"
    [ "$#" -ge 1 ] || -die $USAGE

    local course=$1; shift

    containers="$@"
    if [[ -z "$containers" ]]; then
        pattern="${course}-x-"
        containers=$(docker ps \
                            --filter "name=$pattern" \
                            --format '{{.Names}}')
    fi
    for container in $containers; do
        port=$(docker port $container | cut -d: -f2)
        echo ========== $container;
        curl -k --silent http://localhost:$port/api/kernels?token=$container | \
            python3 -c "import sys, pprint, json; pprint.pprint(json.loads(sys.stdin.read()))"
    done
}

####################

@declare-subcommand list-courses
function list-courses() {
    local USAGE="Usage: $FUNCNAME"
    [ "$#" -eq 0 ] || -die $USAGE

    cd $NBHROOT/courses || exit 0
    ls
}


@declare-subcommand docker-counts
function docker-counts() {
    echo -n "Running containers "
    docker ps --format '{{.Names}}' | wc -l
    echo -n "Total containers "
    docker ps -a --format '{{.Names}}' | wc -l
}

####################
function -rename-dir() {
    local oldname=$1; shift
    local newname=$1; shift
    [ -d $oldname ] || echo "SOURCE $oldname NOT FOUND"
    [ -d $newname ] && echo "DEST $newname FOUND"
    mv $oldname $newname
}

@declare-subcommand course-rename
function course-rename() {
    local USAGE="Usage: $FUNCNAME oldname newname"
    [ "$#" -eq 2 ] || -die $USAGE

    local old_course=$1; shift
    local new_course=$1; shift

    -compute-course-globals $old_course
    local old_git=$COURSE_git
    local old_notebooks=$COURSE_notebooks
    local old_modules=$COURSE_modules
    local old_static=$COURSE_static
    local old_jupyter=$COURSE_jupyter
    local old_raw=$COURSE_raw
    local old_logs=$COURSE_logs
    local old_build=$COURSE_build

    -compute-course-globals $new_course
    local new_git=$COURSE_git
    local new_notebooks=$COURSE_notebooks
    local new_modules=$COURSE_modules
    local new_static=$COURSE_static
    local new_jupyter=$COURSE_jupyter
    local new_raw=$COURSE_raw
    local new_logs=$COURSE_logs
    local new_build=$COURSE_build

    # check old_course is a known course
    [ -d $old_git ] || -die "Unknown course ${old_course}"
    # check new_course is not a known course
    [ -d $new_git ] && -die "Already existing course ${new_course}"

    # check all containers are down
    echo "Checking for remaining containers"
    local alive=$(docker ps -a --format '{{.Names}}' | grep "^${old_course}-x" | wc -l)
    if [ $alive != 0 ]; then
        local message="Found $alive containers for $old_course"
        message="$message - Delete with nbh course-clean-containers"
        -die $message
    fi
    -rename-dir $old_git $new_git
    -rename-dir $old_notebooks $new_notebooks
    -rename-dir $old_modules $new_modules
    -rename-dir $old_static $new_static
    -rename-dir $old_jupyter $new_jupyter
    -rename-dir $old_raw $new_raw
    -rename-dir $old_logs $new_logs
    -rename-dir $old_build $new_build

    for student_dir in $(echo $NBHROOT/students/*/$old_course); do
        local new_dir=$(sed -e "s,$old_course,$new_course," <<< $student_dir)
        -rename-dir $student_dir $new_dir
    done

}

###########
# if for any reason a user can't be created
# e.g. because of limits in /etc/login.defs
# then things can become nasty for these students
# because a directory is created in /students, but it has the wrong owner
# and a docker containers gets spawned on top of that

# xxx todo : fix that earlier on; should not let the whole thing proceed
# when useradd fails to work

# once the root issue is fixed - again typically in /etc/login.defs
# the solution is to just remove both the directory and docker
# - if relevant - for all these hashes
# in other words, just pretend we've never heard from these people

@declare-subcommand admin-repair-zombies
function admin-repair-zombies() {
    cd $NBHROOT/students

    # locate zombie students as the ones whose dir is owned by root
    zombies=$(find . -maxdepth 1 -user root -print | \
              grep -v '^\.$' | sed -e s,./,,)

    # do this only once
    docker ps --all --format '{{.Names}}' > /tmp/nbh-repair.txt

    for zombie in $zombies; do
        echo -n $zombie " "
        docker=$(grep $zombie /tmp/nbh-repair.txt)
        if [ -d $zombie ]; then
            echo -n "Dir "
            rm -rf $zombie
        fi
        if [ -n "$docker" ] ; then
            echo -n "Doc "
            docker rm $docker >& /dev/null && echo -n "."
        fi
        echo ""
    done
}

# uid allocation
# turns out that out of the box, fedora comes with settings
# in /etc/login.defs that are quite large in terms of subuids
# i.e. each new user eats up a large range of subuids
# this makes me fear a possible need for cleaning up uids at some point
#
# so given a course - typically old-python2-s3, we're going to
# inspect uids that were attached to that course and try to see if there
# has been any activity recently
# if not, well then we can recyckle that uid - and its subuids
#
# the sad thing is, with uids that can go up to 10**9 or so, it's a shame
# that we need to worry about that kind of stuff at all
# it would be very helpful to know the actual minimal width of sub-ids
# required for docker to work properly

@declare-subcommand admin-free-uids
function admin-free-uids() {
    local USAGE="Usage: FUNCNAME course"

    [ "$#" -eq 1 ] || -die $USAGE
    local course=$1; shift

    echo $FUNCNAME on course $course - not yet implemented
}


## don't expose as it's not operational

# ##############################
# # systemd-nspawn tentative code - not finished
# ##############################
# # assuming that the docker image was redone from its dockerfile
# # which is NOT considered here, we update the actual btrfs reference
# # image in $MACHINES
# # of course $MACHINES must sit in a btrfs filesystem
#
# #@declare-subcommand update-course-image-from-docker-to-spawn
# function update-course-image-from-docker-to-spawn() {
#     local USAGE="Usage: $FUNCNAME course"
#     local course=$1; shift
#     local reference=$course.ref
#     local log=$MACHINES/$course.log
#
#     [ -d $MACHINES ] || mkdir -p $MACHINES
#     cd $MACHINES
#
#     [ -d $reference ] || {
#       btrfs subvolume create $reference;
#     }
#
#     ##### stage1 : unwrap in a fresh repo
#     local unwrap=$course.unwrap
#     rm -rf $unwrap
#     mkdir $unwrap
#
#     # create a dummy docker container just to get its image
#     local dummy=$(docker create $course)
#     docker export $dummy | tar -C $unwrap -xf -
#     docker rm $dummy
#
#     #### stage2 : rsync into actual live image
#     [ -d $reference ] || mkdir $reference
#     (echo ========== $(date); rsync -rltpo --delete -i $unwrap/ $reference/) >> $log
#
# }
#
# ####################
# # digression in python: find a free port
# function free-port() {
#     python3 << EOF
# import socket
# from contextlib import closing
# try:
#     with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
#         s.bind(('', 0))
#         print(s.getsockname()[1])
# except:
#     print(0)
# EOF
#     }
#
#
# function -compute-container-globals() {
#     local container=$1; shift
#
#     CONTAINER_nspawn_root=$MACHINES/$container
#}
#
#
##@declare-subcommand spawn-container-in-course-for-student
#function spawn-container-in-course-for-student() {
#    local USAGE="Usage: $COMMAND $FUNCNAME container course student"
#    [ "$#" -eq 3 ] || -die $USAGE
#
#    local container=$1; shift
#    local course=$1; shift
#    local student=$1; shift
#
#    -compute-course-globals $course
#    -compute-student-globals-in-course $student $course
#    -compute-container-globals $container
#
#    local port=$(free-port)
#    local token=$student
#    # cannot use --ephemeral with --template
#    local command="systemd-nspawn
#                    --template=${COURSE_ref}
#                    --directory=${CONTAINER_nspawn_root}
#                    --user=jovyan
#                    --setenv=PATH=/opt/conda/bin
#                    --bind=$STUDENT_course:/home/jovyan/work
#                    --bind=$COURSE_modules:/home/jovyan/modules
#                    --bind=$COURSE_jupyter/jupyter_notebook_config.py:/home/jovyan/.jupyter/jupyter_notebook_config.py
#                    --bind=$COURSE_jupyter/custom.js:/home/jovyan/.jupyter/custom/custom.js
#                    --bind=$COURSE_jupyter/custom.css:/home/jovyan/.jupyter/custom/custom.css"
#    for static in $COURSE_statics; do
#       command="$command
#                     --bind=$NBHROOT/static/$course/$static:/home/jovyan/work/$static"
#    done
#    command="$command
#                   /usr/local/bin/start-notebook.sh
#                   --NotebookApp.port=${port}
#                   --no-browser
#                   --NotebookApp.token=${token}
#"
#
#    echo $command
#    $command
#}
#
#
## inspired by https://seanmcgary.com/posts/nsenter-a-systemd-nspawn-container
## don't expose as it's not operational
##@declare-subcommand enter-spawned-container
#function enter-spawned-container() {
#    local USAGE="Usage: $FUNCNAME container [command]"
#    [ "$#" -ge 1 ] || -die $USAGE
#
#    local container=$1; shift
#
#    local leaderpid=$(machinectl -p Leader show $container | cut "-d=" -f2)
#    command="nsenter --target $leaderpid --mount --uts --ipc --net $@"
#    echo $command
#    $command
#}
#
#
#function status-btrfs() {
#    #command="btrfs subvolume list $MACHINES"
#    #echo ========== $command; $command
#    command="btrfs filesystem df -h $MACHINES"
#    echo ========== $command; $command
#    command="btrfs filesystem df -h $IMAGES"
#    echo ========== $command; $command
#}
#
#function status-devel() {
#    local command="docker ps"
#    echo ========== $command; $command
#    local command="docker ps -a"
#    echo ========== $command; $command
#    local command="machinectl list"
#    echo ========== $command; $command
#    local command=status-btrfs
#    echo ========== $command; $command
#    local command="btrfs subvolume list $MACHINES"
#    echo ========== $command; $command
#}

##############################
USAGE="$COMMAND [-d nbhroot] [-x] subcommand ...
  -d  allows to set another root than $NBHROOT
  -x  turn on debugging
Available subcommands:
"

function list-subcommands() {
    for s in $SUBCOMMANDS; do
        echo $s
    done | sort | sed -e 's,^, * ,'
}

function usage() {
    printf "$USAGE"; list-subcommands;
}

function main() {

    while getopts "d:x" option; do
        case $option in
            d) NBHROOT="$OPTARG"
               # make sure root is absolute
               NBHROOT=$(cd $NBHROOT; pwd -P)
               ;;
            x) DEBUG=true ;;
            ?) >&2 usage; exit 1;;
        esac
    done
    shift $((OPTIND-1))
    # reset OPTIND for subsequent calls to getopts
    OPTIND=1

    # first argument is a subcommand in this file
    local fun="$1"
    if [ -z "$fun" ]; then
        list-subcommands >& 2
        exit 1
    else
        case $(type -t -- $fun) in
            function)
                shift ;;
            *)
                { echo "$fun not a valid subcommand; pick among the following:"
                  list-subcommands
                  } >&2
                exit 1
                ;;
        esac
    fi

    # call subcommand
    $fun "$@"
}


# xxx from older version
# because the outcome of this script goes on stdout,
# so we always write on stderr, but as far as stderr is concerned,
# we want to log it *and* to return it in stderr
# xxx previous redirection system
# main 2> >(tee -a $log >&2) || :


main "$@"
